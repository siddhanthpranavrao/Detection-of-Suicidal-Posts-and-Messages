{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TufU-2YxYM3j"
   },
   "source": [
    "As this code uses Deon's Reddit account to scrape data and relies on models and generated datasets stored on his google drive, it may not be possible to run this code without us sending the required inputs. So in case the project evaluation includes locally testing our code, please contact us for the models and the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPnVamTcvlDm"
   },
   "source": [
    "# CONNECTING TO REDDIT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9H399_IpbUlK",
    "outputId": "d29aaf14-df99-419b-a0d6-8c055d9e2c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Obtaining dependency information for praw from https://files.pythonhosted.org/packages/81/6a/21bc058bcccbe03f6a0895bf1bd60c805f0c526aa4e9bfaac775ed0b299c/praw-7.7.1-py3-none-any.whl.metadata\n",
      "  Downloading praw-7.7.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting prawcore<3,>=2.1 (from praw)\n",
      "  Using cached prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
      "Collecting update-checker>=0.18 (from praw)\n",
      "  Using cached update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from praw) (0.58.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
      "Requirement already satisfied: six in d:\\users_programs\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users_programs\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users_programs\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users_programs\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users_programs\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n",
      "Using cached praw-7.7.1-py3-none-any.whl (191 kB)\n",
      "Installing collected packages: update-checker, prawcore, praw\n",
      "Successfully installed praw-7.7.1 prawcore-2.3.0 update-checker-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZzcinmFmdvej"
   },
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMoOFRHHiRI7",
    "outputId": "bca7aac1-26c7-4957-f787-78dcdcaa9c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\users_programs\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\users_programs\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users_programs\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users_programs\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "odshjdsHj2xK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NsOYRQbDYfWI"
   },
   "outputs": [],
   "source": [
    "# Read-only instance\n",
    "reddit_read_only = praw.Reddit(client_id=\"RjgdYl3titIwKlHeM4bQVg\",         # your client id\n",
    "                               client_secret=\"xlfd2ixfHtiNuLLr12kIM4WQV9CW3A\",      # your client secret\n",
    "                               user_agent=\"Scraping\",check_for_async=False)        # your user agent\n",
    "\n",
    "reddit_authorized = praw.Reddit(client_id=\"RjgdYl3titIwKlHeM4bQVg\",         # your client id\n",
    "                                client_secret=\"xlfd2ixfHtiNuLLr12kIM4WQV9CW3A\",      # your client secret\n",
    "                                user_agent=\"Scraping\",        # your user agent\n",
    "                                username=\"SuicidePrevPythonPrj\",        # your reddit username\n",
    "                                password=\"Asdfghjkl1234567$#\",check_for_async=False)        # your reddit password\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIo8mJFlg390",
    "outputId": "df5a2b95-f94b-4e5b-bd72-bdb5a6801ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SuicidePrevPythonPrj\n"
     ]
    }
   ],
   "source": [
    "print(reddit_authorized.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NI4QWyvZdsXK"
   },
   "outputs": [],
   "source": [
    "subreddit = reddit_read_only.subreddit(\"SuicideWatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Um4tH_D9d7ff",
    "outputId": "92f2475e-1ae1-4880-ae92-83e397a2290d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Name: SuicideWatch\n"
     ]
    }
   ],
   "source": [
    "print(\"Display Name:\", subreddit.display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiMPnpDQvs-L"
   },
   "source": [
    "# EXTRACT POSTS FROM SUBREDDITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oNghryk-i92s"
   },
   "outputs": [],
   "source": [
    "#Get the data from the subreddits mentioned\n",
    "def get_subreddits(subreddits, num_posts):\n",
    "    title = []\n",
    "    text = []\n",
    "    post_id = []\n",
    "    reddit_detail = []\n",
    "\n",
    "    for sub in subreddits:\n",
    "        subreddit_obj = reddit_read_only.subreddit(sub)\n",
    "        for posts in subreddit_obj.top(limit=num_posts):\n",
    "            title.append(posts.title)\n",
    "            text.append(posts.selftext)\n",
    "            post_id.append(posts.id)\n",
    "            reddit_detail.append(posts.subreddit)\n",
    "\n",
    "    res_dict = {\"id\": post_id, \"subreddit\": reddit_detail,\n",
    "                \"title\": title, \"text\": text}\n",
    "\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4wZ_zFJBjlSA"
   },
   "outputs": [],
   "source": [
    "subreddits = ['SuicideWatch', 'depression', 'Anxiety']\n",
    "df1 = pd.DataFrame(data = get_subreddits(subreddits,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "H02Rc9mPjzKL",
    "outputId": "0dea9a8e-ed68-4608-9d19-e7d1880725e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ma96y1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>It’s kinda funny how quickly one can go from “...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9d5go</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Anyone else not want to die and not want to ki...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kbqsnq</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>My mom died 3 hours ago</td>\n",
       "      <td>I thought id be ready for this some day but i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e8gjky</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Raped in front of my girlfriend. feeling like ...</td>\n",
       "      <td>\\n\\nI don't know what to say or do, I just fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnrz57</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>'If you were actually suicidal you'd have kill...</td>\n",
       "      <td>FUCK YOU FUCK YOU FUCK YOU \\nYOU ABSOLUTE DUMB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>rv4ybr</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>I'd rather die than feel like this</td>\n",
       "      <td>School started today and I woke up with my hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>15s26nk</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>How many of yall are raw dogging anxiety and l...</td>\n",
       "      <td>like no medication no therapy ? Because I am a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>11796ss</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Anyone else wake up and instantly feel like th...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>iqahuc</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Anyone else have their health issues brushed o...</td>\n",
       "      <td>\\nKind of a vent post, but has anyone else had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>cmfdoj</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Probably gonna get lost in here.... but</td>\n",
       "      <td>A few months later, I went back  to the restau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     subreddit  \\\n",
       "0      ma96y1  SuicideWatch   \n",
       "1      f9d5go  SuicideWatch   \n",
       "2      kbqsnq  SuicideWatch   \n",
       "3      e8gjky  SuicideWatch   \n",
       "4      jnrz57  SuicideWatch   \n",
       "...       ...           ...   \n",
       "2954   rv4ybr       Anxiety   \n",
       "2955  15s26nk       Anxiety   \n",
       "2956  11796ss       Anxiety   \n",
       "2957   iqahuc       Anxiety   \n",
       "2958   cmfdoj       Anxiety   \n",
       "\n",
       "                                                  title  \\\n",
       "0     It’s kinda funny how quickly one can go from “...   \n",
       "1     Anyone else not want to die and not want to ki...   \n",
       "2                               My mom died 3 hours ago   \n",
       "3     Raped in front of my girlfriend. feeling like ...   \n",
       "4     'If you were actually suicidal you'd have kill...   \n",
       "...                                                 ...   \n",
       "2954                 I'd rather die than feel like this   \n",
       "2955  How many of yall are raw dogging anxiety and l...   \n",
       "2956  Anyone else wake up and instantly feel like th...   \n",
       "2957  Anyone else have their health issues brushed o...   \n",
       "2958            Probably gonna get lost in here.... but   \n",
       "\n",
       "                                                   text  \n",
       "0                                                        \n",
       "1                                                        \n",
       "2     I thought id be ready for this some day but i ...  \n",
       "3      \\n\\nI don't know what to say or do, I just fe...  \n",
       "4     FUCK YOU FUCK YOU FUCK YOU \\nYOU ABSOLUTE DUMB...  \n",
       "...                                                 ...  \n",
       "2954  School started today and I woke up with my hea...  \n",
       "2955  like no medication no therapy ? Because I am a...  \n",
       "2956                                                     \n",
       "2957  \\nKind of a vent post, but has anyone else had...  \n",
       "2958  A few months later, I went back  to the restau...  \n",
       "\n",
       "[2959 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YJ-WGovyuHGp"
   },
   "outputs": [],
   "source": [
    "subreddits2 = ['movies', 'popular', 'books','Jokes']\n",
    "df2 = pd.DataFrame(data = get_subreddits(subreddits2,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kvfyh7u9H-yb"
   },
   "outputs": [],
   "source": [
    "df1.to_csv('redditscraping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "y_gLDYEouCQy"
   },
   "outputs": [],
   "source": [
    "df2.to_csv('non_suicide_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('redditscraping.csv')\n",
    "df2 = pd.read_csv('non_suicide_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc26A7CSUUb5",
    "outputId": "402d8af5-081a-4044-e11f-c8e3f797dd3d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Saved to Google Drive\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Mounting Drive on the file path containing the scraped data.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Saved to Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "# Mounting Drive on the file path containing the scraped data.\n",
    "drive.mount('/content/gdrive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Dpg650BFq3z",
    "outputId": "09d0c5d0-8da3-4c72-e5da-31db457a12f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/NLP\n"
     ]
    }
   ],
   "source": [
    "%cd /content/gdrive/MyDrive/NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sxZQ9CWwIf9"
   },
   "source": [
    "# MERGE BOTH DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hMFOkolbuTDJ"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.to_csv('mergedData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lpUSB-Z9F8_b",
    "outputId": "85099828-82ec-435c-82e1-167589960b1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMwy3-wrGLBk",
    "outputId": "0ddb7347-ef20-4e1d-d36c-10585ee1d3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id     subreddit                                              title  \\\n",
      "0  ma96y1  SuicideWatch  It’s kinda funny how quickly one can go from “...   \n",
      "1  f9d5go  SuicideWatch  Anyone else not want to die and not want to ki...   \n",
      "2  kbqsnq  SuicideWatch                            My mom died 3 hours ago   \n",
      "3  e8gjky  SuicideWatch  Raped in front of my girlfriend. feeling like ...   \n",
      "4  jnrz57  SuicideWatch  'If you were actually suicidal you'd have kill...   \n",
      "\n",
      "                                                text  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2  I thought id be ready for this some day but i ...  \n",
      "3   \\n\\nI don't know what to say or do, I just fe...  \n",
      "4  FUCK YOU FUCK YOU FUCK YOU \\nYOU ABSOLUTE DUMB...  \n"
     ]
    }
   ],
   "source": [
    "scrapedData = pd.read_csv(\"mergedData.csv\")\n",
    "print(scrapedData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "Iywz0PHb2mFV",
    "outputId": "dca2f396-c7a0-4d59-fee9-1c1f4660467a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ma96y1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>It’s kinda funny how quickly one can go from “...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9d5go</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Anyone else not want to die and not want to ki...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kbqsnq</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>My mom died 3 hours ago</td>\n",
       "      <td>I thought id be ready for this some day but i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e8gjky</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Raped in front of my girlfriend. feeling like ...</td>\n",
       "      <td>\\n\\nI don't know what to say or do, I just fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnrz57</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>'If you were actually suicidal you'd have kill...</td>\n",
       "      <td>FUCK YOU FUCK YOU FUCK YOU \\nYOU ABSOLUTE DUMB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>gw4fy6</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>A cop pulls over an old lady for speeding on a...</td>\n",
       "      <td>When she opens her wallet, he notices a concea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8240</th>\n",
       "      <td>fh93cl</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>I was talking to a scammer the other day.</td>\n",
       "      <td>Me: “Hello.”\\n\\nNOT-Microsoft support: “Hello...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8241</th>\n",
       "      <td>ayptmw</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>I like my women like I like my slaves</td>\n",
       "      <td>Educated and free.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242</th>\n",
       "      <td>9fqdph</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>A blonde is overweight, so her doctor puts her...</td>\n",
       "      <td>A blonde is overweight, so her doctor puts her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8243</th>\n",
       "      <td>6pfclj</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>The penguin joke (my favorite joke)</td>\n",
       "      <td>\\nOne day a Cop pulls a van over and when he w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8244 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     subreddit                                              title  \\\n",
       "0     ma96y1  SuicideWatch  It’s kinda funny how quickly one can go from “...   \n",
       "1     f9d5go  SuicideWatch  Anyone else not want to die and not want to ki...   \n",
       "2     kbqsnq  SuicideWatch                            My mom died 3 hours ago   \n",
       "3     e8gjky  SuicideWatch  Raped in front of my girlfriend. feeling like ...   \n",
       "4     jnrz57  SuicideWatch  'If you were actually suicidal you'd have kill...   \n",
       "...      ...           ...                                                ...   \n",
       "8239  gw4fy6         Jokes  A cop pulls over an old lady for speeding on a...   \n",
       "8240  fh93cl         Jokes          I was talking to a scammer the other day.   \n",
       "8241  ayptmw         Jokes              I like my women like I like my slaves   \n",
       "8242  9fqdph         Jokes  A blonde is overweight, so her doctor puts her...   \n",
       "8243  6pfclj         Jokes                The penguin joke (my favorite joke)   \n",
       "\n",
       "                                                   text  \n",
       "0                                                   NaN  \n",
       "1                                                   NaN  \n",
       "2     I thought id be ready for this some day but i ...  \n",
       "3      \\n\\nI don't know what to say or do, I just fe...  \n",
       "4     FUCK YOU FUCK YOU FUCK YOU \\nYOU ABSOLUTE DUMB...  \n",
       "...                                                 ...  \n",
       "8239  When she opens her wallet, he notices a concea...  \n",
       "8240   Me: “Hello.”\\n\\nNOT-Microsoft support: “Hello...  \n",
       "8241                                 Educated and free.  \n",
       "8242  A blonde is overweight, so her doctor puts her...  \n",
       "8243  \\nOne day a Cop pulls a van over and when he w...  \n",
       "\n",
       "[8244 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5CuFjgcvasW"
   },
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kShIn0m6iRJH",
    "outputId": "2fb00b85-dbf5-4812-a6ce-a109fac0d8a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\users_programs\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\users_programs\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\users_programs\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\users_programs\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\users_programs\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\users_programs\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klPUhRAr-fMW",
    "outputId": "0de2c443-065b-4965-c5ac-079297c8800c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Siddhanth P.\n",
      "[nltk_data]     Rao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Error downloading 'punkt' from\n",
      "[nltk_data]     <https://raw.githubusercontent.com/nltk/nltk_data/gh-\n",
      "[nltk_data]     pages/packages/tokenizers/punkt.zip>:   HTTP Error\n",
      "[nltk_data]     503: first byte timeout\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Siddhanth P.\n",
      "[nltk_data]     Rao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Error downloading 'stopwords' from\n",
      "[nltk_data]     <https://raw.githubusercontent.com/nltk/nltk_data/gh-\n",
      "[nltk_data]     pages/packages/corpora/stopwords.zip>:   HTTP Error\n",
      "[nltk_data]     503: first byte timeout\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Siddhanth P.\n",
      "[nltk_data]     Rao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Siddhanth P.\n",
      "[nltk_data]     Rao\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries to process the given text\n",
    " \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    " \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lL4pt_SCiRJI"
   },
   "outputs": [],
   "source": [
    "# Set of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    " \n",
    "# Instantiating a lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "# Function that preprocesses the given text.\n",
    "def cleanText(post):\n",
    "    # Splitting the sentence into words\n",
    "    text = re.sub('[^a-zA-Z]', ' ', post)  #remove special characters\n",
    "    text = text.lower()   \n",
    "    text = text.split(' ')\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    #remove stop words\n",
    "    text = [word for word in text if word not in stop_words]  \n",
    "    \n",
    "    cleanedText = ' '.join(text)\n",
    "    return cleanedText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s59Pgo_yiRJJ",
    "outputId": "62e31336-14b2-4fef-f1cc-cfbc663c24c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     NaN\n",
       "1                                                     NaN\n",
       "2       I thought id be ready for this some day but i ...\n",
       "3        \\n\\nI don't know what to say or do, I just fe...\n",
       "4       FUCK YOU FUCK YOU FUCK YOU \\nYOU ABSOLUTE DUMB...\n",
       "                              ...                        \n",
       "8239    When she opens her wallet, he notices a concea...\n",
       "8240     Me: “Hello.”\\n\\nNOT-Microsoft support: “Hello...\n",
       "8241                                   Educated and free.\n",
       "8242    A blonde is overweight, so her doctor puts her...\n",
       "8243    \\nOne day a Cop pulls a van over and when he w...\n",
       "Name: text, Length: 8244, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapedData['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnGKXRmuL9nW",
    "outputId": "7f9009f3-aaac-4410-f990-353fc019f679"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       It’s kinda funny how quickly one can go from “...\n",
       "1       Anyone else not want to die and not want to ki...\n",
       "2                                 My mom died 3 hours ago\n",
       "3       Raped in front of my girlfriend. feeling like ...\n",
       "4       'If you were actually suicidal you'd have kill...\n",
       "                              ...                        \n",
       "8239    A cop pulls over an old lady for speeding on a...\n",
       "8240            I was talking to a scammer the other day.\n",
       "8241                I like my women like I like my slaves\n",
       "8242    A blonde is overweight, so her doctor puts her...\n",
       "8243                  The penguin joke (my favorite joke)\n",
       "Name: title, Length: 8244, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapedData['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WHfScaGVLCe1"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z1kbc-WwqaI"
   },
   "source": [
    "# ASSIGNING LABELS AND CLEANING THE DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AHlcLAKsHDle"
   },
   "outputs": [],
   "source": [
    "labels = scrapedData['subreddit'].tolist()\n",
    "\n",
    "#Assigning labels to the dataset\n",
    "actualLabels = []\n",
    "for i in range(len(labels)):\n",
    "  if (labels[i] == 'SuicideWatch' or labels[i] == 'depression' or labels[i] == 'Anxiety'):\n",
    "    actualLabels.append(1)\n",
    "  else:\n",
    "    actualLabels.append(0)\n",
    "\n",
    "postText = scrapedData['text'].tolist()\n",
    "postTitle = scrapedData['title'].tolist()\n",
    "\n",
    "l = len(postText)\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(l):\n",
    "  s = postTitle[i]\n",
    "  if (type(postText[i]) != float):\n",
    "    s += ' '\n",
    "    s += postText[i]\n",
    "  #Preprocessing fucntion run for each (postTitle + postText)\n",
    "  corpus.append(cleanText(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-phqFU9WNYBI",
    "outputId": "2e8a10c5-2d5d-4c7e-8e33-ccf2d3f4d4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(actualLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odbRDpcJxCXC"
   },
   "source": [
    "# CONVERTING TEXT TO VECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6lqz_Ub4kyA"
   },
   "source": [
    "IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BfqukVYLJRaK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUiqF-KC45k1"
   },
   "source": [
    " TFIDF VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CsF6xNklKhhI"
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(ngram_range = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0f7TaMNmKngv"
   },
   "outputs": [],
   "source": [
    "tf_vec = tf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FI4hsSXR5HVY"
   },
   "source": [
    "# SPLIT DATASET TO TRAIN,TEST DATA (70% TRAIN,30% TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UuDMGOA-Kny-"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tf_vec, actualLabels, test_size = 0.3, shuffle = True, random_state = 42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFbJ7daQ6Kxk"
   },
   "source": [
    "# NAIVE BAYES CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hSXnKL6z96h",
    "outputId": "f1437cad-171c-4cdc-9dfb-4614015ec975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is  1\n",
      "Best score value is  0.9596187175043328\n"
     ]
    }
   ],
   "source": [
    "#Tuning of hyperparameter alpha\n",
    "parameters = {\"alpha\":[0.001, 0.005, 0.01, 0.075, 0.05, 0.025, 0.1, 0.25, 0.5, 0.75, 1, 5, 10, 50]}\n",
    "\n",
    "#GridSearchCV does an exhaustive search over specified parameter values for an estimator\n",
    "clf= GridSearchCV(MultinomialNB(),parameters, cv=10, scoring= \"accuracy\", return_train_score= True)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#best value of alpha\n",
    "alpha= clf.best_params_[\"alpha\"] \n",
    "score= clf.best_score_\n",
    "print(\"Best alpha value is \", alpha)\n",
    "print(\"Best score value is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CCJza64xz-Gk"
   },
   "outputs": [],
   "source": [
    "#Best value of alpha is 0.5 and we us that with MultinomialNB\n",
    "model1= MultinomialNB(alpha=1)\n",
    "model1.fit(x_train, y_train)\n",
    "y_pred= model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5y3HOIflz-Qd",
    "outputId": "97a56a77-0041-4e91-b030-fcc595d53000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1561\n",
      "           1       0.96      0.96      0.96       913\n",
      "\n",
      "    accuracy                           0.97      2474\n",
      "   macro avg       0.97      0.97      0.97      2474\n",
      "weighted avg       0.97      0.97      0.97      2474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj9CFj1a6gfi"
   },
   "source": [
    "CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "Fv2zEyrQz-ZH",
    "outputId": "651a0369-b4d9-4ba6-848e-0bfb158493d0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the ConfusionMatrixDisplay object\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[\"Class 0\", \"Class 1\"])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cmd.plot(cmap=\"Blues\", ax=ax, values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dcXB_o68voy"
   },
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/9e/b8/ed5f794359d05cd0bffb894c6418da87b93016ee17b669d55c45d1bd5d5b/tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.13.0 from https://files.pythonhosted.org/packages/2f/2f/3c84f675931ce3bcbc7e23acbba1e5d7f05ce769adab48322de57a9f5928/tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ---------------------------------------- 0.0/126.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 126.5/126.5 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/14/ff/10f746c03212fe48576b2c0f5ada73c3400b6d90f769728c4f07656d8b27/protobuf-4.24.2-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.24.2-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/8d/58/ede228c07bdf3780c5332660c89f3c7a37fe8bfb9bd73a97ad2614420bd4/grpcio-1.57.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.57.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.3/5.6 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 1.5/5.6 MB 19.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 3.1/5.6 MB 22.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.8/5.6 MB 25.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 27.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 22.2 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------  1.5/1.5 MB 98.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 47.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/9c/8d/bff87fc722553a5691d8514da5523c23547f3894189ba03b57592e37bdc2/google_auth-2.22.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/da/61/6e9ff8258422d287eec718872fb71e05324356722ab658c8afda25f51539/tensorboard_data_server-0.7.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\users_programs\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\users_programs\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in d:\\users_programs\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users_programs\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users_programs\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users_programs\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\users_programs\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\users_programs\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Downloading tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl (276.6 MB)\n",
      "   ---------------------------------------- 0.0/276.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/276.6 MB 52.5 MB/s eta 0:00:06\n",
      "    --------------------------------------- 4.4/276.6 MB 56.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 7.0/276.6 MB 55.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 9.6/276.6 MB 55.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 12.1/276.6 MB 54.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 14.8/276.6 MB 54.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 16.6/276.6 MB 50.4 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 18.1/276.6 MB 46.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 19.9/276.6 MB 43.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 21.5/276.6 MB 38.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 23.3/276.6 MB 36.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 25.2/276.6 MB 36.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 27.0/276.6 MB 36.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 28.8/276.6 MB 38.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 30.7/276.6 MB 38.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 32.5/276.6 MB 38.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 34.4/276.6 MB 38.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 36.1/276.6 MB 40.9 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 38.0/276.6 MB 38.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 39.7/276.6 MB 40.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.7/276.6 MB 40.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 43.5/276.6 MB 38.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 45.3/276.6 MB 38.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 46.7/276.6 MB 38.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 49.0/276.6 MB 38.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 50.9/276.6 MB 38.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 52.8/276.6 MB 38.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 54.6/276.6 MB 38.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 56.1/276.6 MB 40.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 58.3/276.6 MB 38.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 60.1/276.6 MB 38.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 61.8/276.6 MB 38.5 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 63.1/276.6 MB 36.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 65.0/276.6 MB 36.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 66.8/276.6 MB 38.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 68.7/276.6 MB 36.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 70.3/276.6 MB 36.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 72.2/276.6 MB 38.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 73.9/276.6 MB 36.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 75.6/276.6 MB 38.5 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 77.2/276.6 MB 36.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 79.0/276.6 MB 36.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 81.1/276.6 MB 38.6 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 83.0/276.6 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 84.8/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 86.4/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 88.4/276.6 MB 38.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 90.1/276.6 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 91.8/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 93.5/276.6 MB 36.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 95.4/276.6 MB 36.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 97.5/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 99.6/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 101.8/276.6 MB 40.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------ 103.6/276.6 MB 43.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------ 105.5/276.6 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 107.4/276.6 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 109.3/276.6 MB 43.7 MB/s eta 0:00:04\n",
      "   --------------- ----------------------- 111.1/276.6 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 113.0/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 114.8/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 116.7/276.6 MB 38.5 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 118.5/276.6 MB 38.6 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 120.3/276.6 MB 38.6 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 122.2/276.6 MB 38.6 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 124.0/276.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 125.9/276.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 127.7/276.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 129.6/276.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 131.1/276.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 131.1/276.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 131.7/276.6 MB 28.5 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 133.5/276.6 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 136.1/276.6 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 138.8/276.6 MB 31.1 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 141.6/276.6 MB 50.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 144.6/276.6 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 146.4/276.6 MB 54.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 148.2/276.6 MB 50.4 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 150.1/276.6 MB 46.7 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 151.9/276.6 MB 43.5 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 153.8/276.6 MB 38.5 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 155.1/276.6 MB 36.3 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 157.0/276.6 MB 38.6 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 158.4/276.6 MB 36.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 160.3/276.6 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 162.1/276.6 MB 36.4 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 163.6/276.6 MB 34.4 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 165.4/276.6 MB 34.6 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 167.0/276.6 MB 36.3 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 169.1/276.6 MB 38.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 171.0/276.6 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 172.8/276.6 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 174.7/276.6 MB 38.5 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 175.8/276.6 MB 36.3 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 177.7/276.6 MB 38.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 179.5/276.6 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 181.3/276.6 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 182.6/276.6 MB 36.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 184.6/276.6 MB 34.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 186.4/276.6 MB 36.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 187.8/276.6 MB 34.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 189.7/276.6 MB 36.3 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 191.5/276.6 MB 36.3 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 193.1/276.6 MB 36.4 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 195.0/276.6 MB 36.4 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 196.9/276.6 MB 38.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 198.7/276.6 MB 38.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 200.5/276.6 MB 38.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 202.4/276.6 MB 38.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 203.9/276.6 MB 38.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 206.1/276.6 MB 40.9 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 207.9/276.6 MB 38.6 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 209.7/276.6 MB 40.9 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 211.6/276.6 MB 38.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 213.4/276.6 MB 36.3 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 215.2/276.6 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 217.1/276.6 MB 38.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 219.0/276.6 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 220.8/276.6 MB 38.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 222.6/276.6 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 224.4/276.6 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 225.7/276.6 MB 36.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 227.5/276.6 MB 36.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 229.4/276.6 MB 38.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 231.2/276.6 MB 36.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 233.0/276.6 MB 36.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 234.9/276.6 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 236.6/276.6 MB 38.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 238.5/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 240.4/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 242.2/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 244.1/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 245.9/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 247.8/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 249.6/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 251.5/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 253.4/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 255.2/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 257.1/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 258.8/276.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 259.1/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 259.1/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 259.1/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 259.1/276.6 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 259.6/276.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 262.8/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 265.3/276.6 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 267.9/276.6 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  270.7/276.6 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  273.4/276.6 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  275.9/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 276.6/276.6 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.57.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 2.4/4.3 MB 51.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 46.0 MB/s eta 0:00:00\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.7/1.7 MB 52.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 36.0 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.9/24.4 MB 62.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 5.3/24.4 MB 56.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.1/24.4 MB 57.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 10.9/24.4 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.8/24.4 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.0/24.4 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.9/24.4 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.6/24.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.4 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.24.2-cp310-abi3-win_amd64.whl (430 kB)\n",
      "   ---------------------------------------- 0.0/430.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 430.4/430.4 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 440.8/440.8 kB 26.9 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 181.8/181.8 kB 10.7 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: libclang, flatbuffers, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.57.0 keras-2.13.1 libclang-16.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-gNPc2SjnbU3"
   },
   "outputs": [],
   "source": [
    "\"\"\" Implementing an LSTM Model \"\"\"\n",
    "\n",
    "# Importing necessary libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6qG28lw7YII"
   },
   "source": [
    "# TOKENIZER (VECTORIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "h-cvOnBDnt3U"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "6ENG0FUpn5kz"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ChMeAd9LoDhw"
   },
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences(corpus)\n",
    "padded_sequence = pad_sequences(sequence, padding = 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWOzW1_n7ekZ"
   },
   "source": [
    "# TRAIN,TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yaSfi9rToJ9P"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequence, actualLabels, test_size = 0.3, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW9NWlB_7lB9"
   },
   "source": [
    "# GLoVE EMBEDDING MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-ooXHZDoSVc",
    "outputId": "65fae59e-ceb5-4c97-ca93-32cf9461b62c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Used a api of globe for faster access\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3-_ZGr63pQKv"
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = values[1:]\n",
    "        vector = np.asarray(vector, dtype='float32')\n",
    "        embeddings_index[word] = vector\n",
    "\n",
    "embeddings_matrix = np.zeros((vocab_size,100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Y2mtK5T7tr2"
   },
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8kJkt9bkpy8I"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 100, weights = [embeddings_matrix], trainable = False))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azIyrO4Up9O4",
    "outputId": "338b2aab-4a59-4664-d988-83368082718b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         2087300   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 64)          34048     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 64)                24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2148293 (8.20 MB)\n",
      "Trainable params: 60993 (238.25 KB)\n",
      "Non-trainable params: 2087300 (7.96 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "p1IS85kHqAS_"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5eP_AefqR6k",
    "outputId": "14f1f3e9-1893-4d3d-e9bc-ee4fdfe69d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  3/181 [..............................] - ETA: 1:17:36 - loss: 0.6866 - accuracy: 0.5312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_test)\n\u001b[0;32m      4\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_test)\n\u001b[1;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m (x_test, y_test))\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mD:\\Users_Programs\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size = 32, epochs = 10, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sQYSGx6u4Hg",
    "outputId": "ba96938b-302c-4c80-e5c3-ded1ffedea9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 70s 892ms/step - loss: 0.1021 - accuracy: 0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10208655893802643, 0.9715202450752258]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMYAilkcLmYG"
   },
   "outputs": [],
   "source": [
    "model.save('./lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmNk0szYvBgn"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5R5ZBNrvVLP"
   },
   "outputs": [],
   "source": [
    "pred = pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hJs5JeQvYAe",
    "outputId": "a8911599-a2ea-41c1-ad2d-923c47776052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.97      0.98      1608\n",
      "        True       0.95      0.98      0.96       885\n",
      "\n",
      "    accuracy                           0.97      2493\n",
      "   macro avg       0.97      0.97      0.97      2493\n",
      "weighted avg       0.97      0.97      0.97      2493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QttNwbJM76Cg"
   },
   "source": [
    "# LOAD SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMnsDGqr_LVp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "lstm_model=load_model(\"lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zp9dbI6qMOf1"
   },
   "outputs": [],
   "source": [
    "pred_lstm = lstm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nw5kKM3Z_phr"
   },
   "outputs": [],
   "source": [
    "pred_lstm = pred_lstm >0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOko1Rnr_ukX",
    "outputId": "69600c4f-6cfb-44c9-ee54-f1133507dfe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.97      0.98      1608\n",
      "        True       0.95      0.98      0.96       885\n",
      "\n",
      "    accuracy                           0.97      2493\n",
      "   macro avg       0.97      0.97      0.97      2493\n",
      "weighted avg       0.97      0.97      0.97      2493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_lstm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "WYilEuKg20xO",
    "outputId": "7c6e3f49-0b6b-46cd-8547-ceda6c8fb9ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_lstm)\n",
    "f = sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta7vo4jLB-3h"
   },
   "source": [
    "# TESTING LSTM AND NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzPs2PIhMwUm"
   },
   "outputs": [],
   "source": [
    "def predict_naiveb(model,s):\n",
    "    new_text = cleanText(s)\n",
    "    vec = tf.transform([new_text])\n",
    "    res = model.predict(vec)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouPldBc6_1zf"
   },
   "outputs": [],
   "source": [
    "def predict_lstm(model,s):\n",
    "    new_text = cleanText(s)\n",
    "    sequence = tokenizer.texts_to_sequences([new_text])\n",
    "    padded_sequence = pad_sequences(sequence,padding='post',)\n",
    "    res = model.predict(padded_sequence)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHgqb9sk9uHd"
   },
   "outputs": [],
   "source": [
    "text = ['I dont want to live any more','Tie the rope','Tie the rope!!! I want to die',\n",
    "        'My dog died in an accident','I want to take my own life','I want to end it all','I am fed up of seeing RCB performance','Live long and prosper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPoiWijgPPL4",
    "outputId": "3ad68c4a-c9d6-4bda-a125-9e679225bd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I dont want to live any more - True\n",
      "Tie the rope - False\n",
      "Tie the rope!!! I want to die - True\n",
      "My dog died in an accident - False\n",
      "I want to take my own life - True\n",
      "I want to end it all - True\n",
      "I am fed up of seeing RCB performance - False\n",
      "Live long and prosper - True\n"
     ]
    }
   ],
   "source": [
    "for t in text:\n",
    "    res = predict_naiveb(model1,t)\n",
    "    print(\"{} - {}\".format(t, res[0]>0.50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEXOoCVdFc6B",
    "outputId": "1f02a4f8-ee97-4c25-99e2-a6812754d6e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I dont want to live any more :0.90 - True\n",
      "Tie the rope :0.17 - False\n",
      "Tie the rope!!! I want to die :0.70 - True\n",
      "My dog died in an accident :0.37 - False\n",
      "I want to take my own life :0.94 - True\n",
      "I want to end it all :0.62 - True\n",
      "I am fed up of seeing RCB performance :0.26 - False\n",
      "Live long and prosper :0.50 - True\n"
     ]
    }
   ],
   "source": [
    "for t in text:\n",
    "    res = predict_lstm(lstm_model,t)\n",
    "    print(\"{} :{:.2f} - {}\".format(t, res[0],res[0] > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smNT2Mia8WiK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Project_Group_15_Code (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
